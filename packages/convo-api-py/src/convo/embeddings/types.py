from dataclasses import dataclass
from typing import Any, Callable, Dict, List, Optional

from nano_graphrag._llm import gpt_4o_complete, gpt_4o_mini_complete
from pydantic import BaseModel


class DocumentEmbeddingRequest(BaseModel):
    """Defines properties for generating embeddings for a given document"""

    # location of the document to index. Can be a file path, url or s3 url
    # if set to "inline" the content of the inlineContent prop will be used.
    location: str

    textCol: Optional[str] = "text"

    embeddingCol: Optional[str] = "embedding"

    # The content type of the document
    contentType: Optional[str] = None

    # Inline content
    inlineContent: Optional[str] = None

    # Name of the table to insert embeddings into
    embeddingsTable: str = "TextBlob"

    # Additional column values to insert into vector index table
    cols: Optional[Dict[str, Any]] = None

    # If true embeddings for the document are generated by not inserted in to the embeddings table
    dryRun: bool = False

    contentTypeCol: Optional[str] = None

    contentCategoryCol: Optional[str] = None

    contentCategoryFilter: Optional[List[str]] = None

    clearMatching: Optional[List[str]] = None

    chunk_size: int = 300

    chunk_overlap: int = 20

    max_characters: int = 1_000

    chunk_by_title: bool = True


class DocumentConversionRequest(BaseModel):
    srcPath: str
    destPath: str


@dataclass
class GraphRagConfig:
    best_model_func: Callable = gpt_4o_complete
    best_model_max_token_size: int = 32768
    best_model_max_async: int = 16
    cheap_model_func: callable = gpt_4o_mini_complete
    cheap_model_max_token_size: int = 32768
    cheap_model_max_async: int = 16
    tiktoken_model_name: str = "gpt-4o"
    entity_summary_to_max_tokens: int = 500
    entity_extract_max_gleaning: int = 1


@dataclass
class EmbededChunk:
    vec: List[float]
    text: str
